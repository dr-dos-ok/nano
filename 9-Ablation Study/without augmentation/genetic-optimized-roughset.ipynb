{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of target vector :  (1000,)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix\n",
    "from deap import creator, base, tools, algorithms\n",
    "import random\n",
    "import numpy\n",
    "from scipy import interpolate\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import time\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"reduced_dataset.csv\",  header=None)\n",
    "y = df.iloc[:, 0]\n",
    "\n",
    "print(\"Shape of target vector : \",y.shape)\n",
    "\n",
    "column_numbers = [x for x in range(df.shape[1])]  # list of columns' integer indices\n",
    "\n",
    "column_numbers.remove(0) #removing column integer index 0\n",
    "Features= df.iloc[:, column_numbers] #return all columns except the 0th column\n",
    "\n",
    "X=Features\n",
    "\n",
    "# Form training, test, and validation sets\n",
    "X_trainAndTest, X_validation, y_trainAndTest, y_validation = train_test_split(X, y, test_size=0.20, random_state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_trainAndTest, y_trainAndTest, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Feature subset fitness function\n",
    "def getFitness(individual, X_train, X_test, y_train, y_test, evaluation=False):\n",
    "\n",
    "\tcols = [index for index in range(len(individual)) if individual[index] == 0]\n",
    "\tX_trainParsed = X_train.drop(X_train.columns[cols], axis=1)\n",
    "\tX_trainOhFeatures = pd.get_dummies(X_trainParsed)\n",
    "\tX_testParsed = X_test.drop(X_test.columns[cols], axis=1)\n",
    "\tX_testOhFeatures = pd.get_dummies(X_testParsed)\n",
    "\n",
    "\t# Remove any columns that aren't in both the training and test sets\n",
    "\tsharedFeatures = set(X_trainOhFeatures.columns) & set(X_testOhFeatures.columns)\n",
    "\tremoveFromTrain = set(X_trainOhFeatures.columns) - sharedFeatures\n",
    "\tremoveFromTest = set(X_testOhFeatures.columns) - sharedFeatures\n",
    "\tX_trainOhFeatures = X_trainOhFeatures.drop(list(removeFromTrain), axis=1)\n",
    "\tX_testOhFeatures = X_testOhFeatures.drop(list(removeFromTest), axis=1)\n",
    "\n",
    "\t# Apply logistic regression on the data, and calculate accuracy\n",
    "\tclf = LogisticRegression()\n",
    "\tclf.fit(X_trainOhFeatures, y_train)\n",
    "\tpredictions = clf.predict(X_testOhFeatures)\n",
    "\taccuracy = accuracy_score(y_test, predictions)\n",
    "\n",
    "\tif evaluation == False:\t\n",
    "\t\treturn (accuracy,)\n",
    "\n",
    "#\tresults = confusion_matrix(y_test, predictions)\n",
    "\tprecision = precision_score(y_test, predictions)\n",
    "\trecall = recall_score(y_test, predictions)\n",
    "    # Print classification report\n",
    "\tprint(\"Classification Report:\")\n",
    "\tprint(classification_report(y_test, predictions, digits=4))\n",
    "    \n",
    "\treturn (accuracy, precision, recall)\n",
    "\n",
    "# Create Individual/Classes\n",
    "creator.create(\"FitnessMax\", base.Fitness, weights=(1.0,))\n",
    "creator.create(\"Individual\", list, fitness=creator.FitnessMax)\n",
    "\n",
    "# Create Toolbox/Base Class\n",
    "toolbox = base.Toolbox()\n",
    "toolbox.register(\"attr_bool\", random.randint, 0, 1)\n",
    "toolbox.register(\"individual\", tools.initRepeat, creator.Individual, toolbox.attr_bool, len(X.columns) - 1)\n",
    "toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n",
    "toolbox.register(\"evaluate\", getFitness, X_train=X_train, X_test=X_test, y_train=y_train, y_test=y_test, evaluation=False)\n",
    "toolbox.register(\"mate\", tools.cxOnePoint)\n",
    "toolbox.register(\"mutate\", tools.mutFlipBit, indpb=0.05)\n",
    "toolbox.register(\"select\", tools.selTournament, tournsize=3)\n",
    "\n",
    "\n",
    "def getHof():\n",
    "\t# Initialize variables to use eaSimple\n",
    "\tnumPop = 10\n",
    "\tnumGen = 10\n",
    "\tpop = toolbox.population(n=numPop)\n",
    "\thof = tools.HallOfFame(numPop * numGen)\n",
    "\tstats = tools.Statistics(lambda ind: ind.fitness.values)\n",
    "\tstats.register(\"avg\", numpy.mean)\n",
    "\tstats.register(\"std\", numpy.std)\n",
    "\tstats.register(\"min\", numpy.min)\n",
    "\tstats.register(\"max\", numpy.max)\n",
    "\tpop, log = algorithms.eaSimple(pop, toolbox, cxpb=0.5, mutpb=0.2, ngen=numGen, stats=stats, halloffame=hof, verbose=False)\n",
    "\treturn hof\n",
    "\n",
    "def getMetrics(hof):\n",
    "\n",
    "\ttestAccuracyList = []\n",
    "\tvalidationAccuracyList = []\n",
    "\tindividualList = []\n",
    "\tfor individual in hof:\n",
    "\t\ttestAccuracy = individual.fitness.values\n",
    "\t\tvalidationAccuracy = getFitness(individual, X_trainAndTest, X_validation, y_trainAndTest, y_validation, evaluation=False)\n",
    "\t\ttestAccuracyList.append(testAccuracy[0])\n",
    "\t\tvalidationAccuracyList.append(validationAccuracy[0])\n",
    "\t\tindividualList.append(individual)\n",
    "\ttestAccuracyList.reverse()\n",
    "\tvalidationAccuracyList.reverse()\n",
    "\treturn testAccuracyList, validationAccuracyList, individualList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9730    0.9000    0.9351        40\n",
      "           1     0.9675    0.9917    0.9794       120\n",
      "\n",
      "    accuracy                         0.9688       160\n",
      "   macro avg     0.9702    0.9458    0.9572       160\n",
      "weighted avg     0.9689    0.9688    0.9683       160\n",
      "\n",
      "Test accuracy with all features: \t0.96875\n",
      "Validation accuracy with all features: \t0.98\n",
      "Test time : 10.053283929824829\n",
      "Precision : \t0.967479674796748\tRecall : 0.9916666666666667\n",
      "Number of Features : 5000\n",
      "===================================================\n",
      "\n",
      "---Optimal Feature Subset(s)---\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     1.0000    0.9000    0.9474        40\n",
      "           1     0.9677    1.0000    0.9836       120\n",
      "\n",
      "    accuracy                         0.9750       160\n",
      "   macro avg     0.9839    0.9500    0.9655       160\n",
      "weighted avg     0.9758    0.9750    0.9745       160\n",
      "\n",
      "Number Features In Subset: \t2521\n",
      "Test Time: 4.015583515167236\n",
      "Test Accuracy: \t\t0.975\n",
      "Validation Accuracy: \t\t0.99\n",
      "Precision : \t0.967741935483871\tRecall : 1.0\n",
      "========================================\n",
      "========================================\n",
      "---BUILD TIME : 515.6130492687225 ---\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "\tindividual = [1 for i in range(5000)]\n",
    "\tstart = time.time()\n",
    "\ttestAccuracy, precision, recall = getFitness(individual, X_train, X_test, y_train, y_test, evaluation=True)\n",
    "\tend = time.time()\n",
    "\tvalidationAccuracy = getFitness(individual, X_trainAndTest, X_validation, y_trainAndTest, y_validation, evaluation=False)\n",
    "\tprint('Test accuracy with all features: \\t' + str(testAccuracy))\n",
    "\tprint('Validation accuracy with all features: \\t' + str(validationAccuracy[0]))\n",
    "\tprint(\"Test time : \" + str(end-start))\n",
    "\tprint('Precision : \\t' + str(precision) + '\\tRecall : ' + str(recall))\n",
    "\tprint(\"Number of Features : \" + str(len(individual)))\n",
    "\n",
    "\tbuild_start = time.time()\n",
    "\thof = getHof()\n",
    "\ttestAccuracyList, validationAccuracyList, individualList = getMetrics(hof)\n",
    "\tbuild_end = time.time()\n",
    "\t# Get a list of subsets that performed best on validation data\n",
    "\tmaxValAccSubsetIndicies = [index for index in range(len(validationAccuracyList)) if validationAccuracyList[index] == max(validationAccuracyList)]\n",
    "\tmaxValIndividuals = [individualList[index] for index in maxValAccSubsetIndicies]\n",
    "\tmaxValSubsets = [[list(X)[index] for index in range(len(individual)) if individual[index] == 1] for individual in maxValIndividuals]\n",
    "\n",
    "\n",
    "\t# WORKING ON HOF\n",
    "\tcount = [0 for i in range(len(X.columns))]\n",
    "\tfor subset in hof :\n",
    "\t\ti = 0\n",
    "\t\tfor feature in subset :\n",
    "\t\t\tif feature :\n",
    "\t\t\t\tcount[i] += 1\n",
    "\t\t\ti += 1\n",
    "\thof_feature_count = []\n",
    "\tfor index in range(len(count)) :\n",
    "\t\thof_feature_count.append([ list(X)[index], count[index] ])\n",
    "\tprint (\"===================================================\")\n",
    "\n",
    "\t#Rank Features\n",
    "\tcount = [0 for i in range(len(X.columns))]\n",
    "\trank =  [i for i in range(len(X.columns))]\n",
    "\tfor subset in individualList :\n",
    "\t\ti = 0\n",
    "\t\tfor count_index in subset :\n",
    "\t\t\tcount[i] += count_index\n",
    "\t\t\ti += 1\n",
    "\tfor i in range(len(count)): \n",
    "\t\tmax_idx = i\n",
    "\t\tfor j in range(i+1, len(count)):\n",
    "\t\t\tif count[max_idx] < count[j]:\n",
    "\t\t\t\tmax_idx = j\n",
    "\t\tcount[i], count[max_idx] = count[max_idx], count[i]\n",
    "\t\trank[i], rank[max_idx] = rank[max_idx], rank[i]\n",
    "\n",
    "\tbest_features = [list(X)[index] for index in rank[:10]]\n",
    "\n",
    "\t#Print Features Subsets\n",
    "\tprint('\\n---Optimal Feature Subset(s)---\\n')\n",
    "\tfor index in range(len(maxValAccSubsetIndicies)):\n",
    "\n",
    "\t\tstart = time.time()\n",
    "\t\ttestAccuracy, precision, recall = getFitness(maxValIndividuals[index], X_train, X_test, y_train, y_test, evaluation=True)\n",
    "\t\tend = time.time()\n",
    "\n",
    "\t\tprint('Number Features In Subset: \\t' + str(len(maxValSubsets[index])))\n",
    "\t\tprint('Test Time: ' + str(end-start))\n",
    "\t\tprint('Test Accuracy: \\t\\t' + str(testAccuracy))\n",
    "\t\tprint('Validation Accuracy: \\t\\t' + str(validationAccuracyList[maxValAccSubsetIndicies[index]]))\n",
    "\t\tprint('Precision : \\t' + str(precision) + '\\tRecall : ' + str(recall))\n",
    "\t\tprint('========================================')\n",
    "\t\tprint('========================================')\n",
    "\n",
    "\n",
    "\tprint(\"---BUILD TIME : \" + str(build_end-build_start) + \" ---\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
